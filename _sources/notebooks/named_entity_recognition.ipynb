{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q datasets accelerate seqeval transformers \n!pip install gensim==4.1.2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-17T05:23:52.441708Z","iopub.execute_input":"2022-02-17T05:23:52.44216Z","iopub.status.idle":"2022-02-17T05:24:13.226907Z","shell.execute_reply.started":"2022-02-17T05:23:52.442054Z","shell.execute_reply":"2022-02-17T05:24:13.225997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset, load_metric\nfrom transformers import (\n    AutoTokenizer, \n    DataCollatorForTokenClassification, \n    AutoModelForTokenClassification\n)\n\nfrom accelerate import Accelerator\nimport gensim.downloader as api\nimport gradio as gr\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch import optim","metadata":{"execution":{"iopub.status.busy":"2022-02-16T06:35:15.362115Z","iopub.execute_input":"2022-02-16T06:35:15.362392Z","iopub.status.idle":"2022-02-16T06:35:21.783664Z","shell.execute_reply.started":"2022-02-16T06:35:15.362357Z","shell.execute_reply":"2022-02-16T06:35:21.782923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = 'bert-base-cased'\nraw_datasets = load_dataset(\"conllpp\")","metadata":{"execution":{"iopub.status.busy":"2022-02-16T06:35:25.805883Z","iopub.execute_input":"2022-02-16T06:35:25.806303Z","iopub.status.idle":"2022-02-16T06:35:36.212039Z","shell.execute_reply.started":"2022-02-16T06:35:25.806268Z","shell.execute_reply":"2022-02-16T06:35:36.211383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T06:35:39.245712Z","iopub.execute_input":"2022-02-16T06:35:39.245967Z","iopub.status.idle":"2022-02-16T06:35:45.011717Z","shell.execute_reply.started":"2022-02-16T06:35:39.245937Z","shell.execute_reply":"2022-02-16T06:35:45.010873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_row_1 = raw_datasets['train'][0]\ninputs = tokenizer(train_row_1['tokens'], is_split_into_words=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T06:35:47.562766Z","iopub.execute_input":"2022-02-16T06:35:47.563023Z","iopub.status.idle":"2022-02-16T06:35:47.571429Z","shell.execute_reply.started":"2022-02-16T06:35:47.562992Z","shell.execute_reply":"2022-02-16T06:35:47.570675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = raw_datasets['train'].features['ner_tags'].feature.names\nids = range(len(labels))\nid2label = dict(zip(ids, labels))\n\nid2label","metadata":{"execution":{"iopub.status.busy":"2022-02-16T06:35:50.124779Z","iopub.execute_input":"2022-02-16T06:35:50.125435Z","iopub.status.idle":"2022-02-16T06:35:50.133142Z","shell.execute_reply.started":"2022-02-16T06:35:50.125395Z","shell.execute_reply":"2022-02-16T06:35:50.13247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def align_tokens_and_labels(word_ids, labels):\n    previous_word_id = None\n    new_labels = []\n    \n    for word_id in word_ids:\n        \n        if word_id!=previous_word_id:\n            label = -100 if word_id==None else labels[word_id]\n        elif word_id==None:\n            label = -100\n        else:\n            label = labels[word_id]\n            if label%2==1:\n                label += 1\n                \n        previous_word_id = word_id\n        new_labels.append(label)\n                \n    return new_labels","metadata":{"execution":{"iopub.status.busy":"2022-02-16T06:35:50.566648Z","iopub.execute_input":"2022-02-16T06:35:50.567155Z","iopub.status.idle":"2022-02-16T06:35:50.57495Z","shell.execute_reply.started":"2022-02-16T06:35:50.567119Z","shell.execute_reply":"2022-02-16T06:35:50.572243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ner_labels = train_row_1['ner_tags']\ninputs = tokenizer(train_row_1['tokens'], is_split_into_words=True)\nword_ids = inputs.word_ids()\n\nalign_tokens_and_labels(word_ids, ner_labels)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T06:35:51.104899Z","iopub.execute_input":"2022-02-16T06:35:51.105647Z","iopub.status.idle":"2022-02-16T06:35:51.112502Z","shell.execute_reply.started":"2022-02-16T06:35:51.105607Z","shell.execute_reply":"2022-02-16T06:35:51.111663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_inputs_and_labels(ds):\n    inputs = tokenizer(ds['tokens'], truncation=True, padding=True, is_split_into_words=True)\n    labels_batch = ds['ner_tags']\n    \n    new_labels = []\n    for idx, labels in enumerate(labels_batch):\n        word_ids = inputs.word_ids(idx)\n        new_label = align_tokens_and_labels(word_ids, labels)\n        new_labels.append(new_label)\n        \n    inputs['labels'] = new_labels\n    return inputs\n\nprepared_datasets = raw_datasets.map(\n    prepare_inputs_and_labels, \n    batched=True, \n    remove_columns=raw_datasets['train'].column_names\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T06:35:53.754485Z","iopub.execute_input":"2022-02-16T06:35:53.755128Z","iopub.status.idle":"2022-02-16T06:35:59.199548Z","shell.execute_reply.started":"2022-02-16T06:35:53.755093Z","shell.execute_reply":"2022-02-16T06:35:59.198821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 16\ncollate_fn = DataCollatorForTokenClassification(tokenizer=tokenizer)\n\n# training dataloader\ntrain_dl = DataLoader(\n    prepared_datasets['train'], \n    batch_size=batch_size, \n    shuffle=True, \n    collate_fn=collate_fn\n    )\n\n# validation dataloader\nval_dl = DataLoader(\n    prepared_datasets['validation'], \n    batch_size=batch_size, \n    shuffle=True, \n    collate_fn=collate_fn\n    )\n\n# test dataloader\ntest_dl = DataLoader(\n    prepared_datasets['test'], \n    batch_size=batch_size, \n    shuffle=True, \n    collate_fn=collate_fn\n    )","metadata":{"execution":{"iopub.status.busy":"2022-02-16T06:36:00.604063Z","iopub.execute_input":"2022-02-16T06:36:00.604666Z","iopub.status.idle":"2022-02-16T06:36:00.610706Z","shell.execute_reply.started":"2022-02-16T06:36:00.604625Z","shell.execute_reply":"2022-02-16T06:36:00.609632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained(\n    checkpoint, \n    num_labels=len(labels)\n    )\nopt = optim.AdamW(model.parameters(), lr=1.23e-4)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T06:37:37.653248Z","iopub.execute_input":"2022-02-16T06:37:37.653912Z","iopub.status.idle":"2022-02-16T06:37:40.021326Z","shell.execute_reply.started":"2022-02-16T06:37:37.653877Z","shell.execute_reply":"2022-02-16T06:37:40.020594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accelerator = Accelerator()\ntrain_dl, val_dl, test_dl, model, opt = accelerator.prepare(\n    train_dl, \n    val_dl, \n    test_dl, \n    model, \n    opt\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T06:37:54.303886Z","iopub.execute_input":"2022-02-16T06:37:54.304152Z","iopub.status.idle":"2022-02-16T06:37:54.314506Z","shell.execute_reply.started":"2022-02-16T06:37:54.304123Z","shell.execute_reply":"2022-02-16T06:37:54.313692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metric = load_metric('seqeval')\n\ntargets = ['O', 'B-PER', 'I-PER', 'O', 'O', 'O']\npredictions = ['O', 'B-PER', 'O', 'O', 'O', 'O']\n\nmetric.compute(predictions=[predictions], references=[targets])","metadata":{"execution":{"iopub.status.busy":"2022-02-16T06:37:55.502913Z","iopub.execute_input":"2022-02-16T06:37:55.503413Z","iopub.status.idle":"2022-02-16T06:37:56.056648Z","shell.execute_reply.started":"2022-02-16T06:37:55.503373Z","shell.execute_reply":"2022-02-16T06:37:56.055958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_preds_and_labels(preds, targets):\n    preds = preds.detach().cpu()\n    preds = preds.argmax(dim=-1)\n    targets = targets.detach().cpu()\n\n    true_targets = [\n        [labels[t.item()] for t in target if t!=-100] \n        for target in targets\n        ]\n    true_preds = [\n        [labels[p.item()] for p, t in zip(pred, target) if t!=-100] \n        for pred, target in zip(preds, targets)\n        ]\n\n    return true_preds, true_targets","metadata":{"execution":{"iopub.status.busy":"2022-02-16T06:37:56.329828Z","iopub.execute_input":"2022-02-16T06:37:56.330044Z","iopub.status.idle":"2022-02-16T06:37:56.336391Z","shell.execute_reply.started":"2022-02-16T06:37:56.330018Z","shell.execute_reply":"2022-02-16T06:37:56.335435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first_batch = next(iter(train_dl))\n\npreds = model(**first_batch)\nprocess_preds_and_labels(preds.logits, first_batch['labels'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_training_loop(train_dl):\n    model.train()\n    for batch in tqdm(train_dl, total=len(train_dl)):\n        opt.zero_grad()\n        out = model(**batch)\n        accelerator.backward(out.loss)\n        opt.step()\n        \n        # convert target labels and predictions to string format for computing accuracy\n        preds, labels = process_preds_and_labels(out.logits, batch['labels'])\n        # add the target labels and predictions of this batch to seqeval\n        metric.add_batch(predictions=preds, references=labels)\n\ndef run_evaluation_loop(test_dl):\n    model.eval()\n    with torch.no_grad():\n        for batch in tqdm(test_dl, total=len(test_dl)):\n            out = model(**batch)\n            \n            # convert target labels and predictions to string format for computing accuracy\n            preds, labels = process_preds_and_labels(out.logits, batch['labels'])\n            # add the target labels and predictions of this batch to seqeval\n            metric.add_batch(predictions=preds, references=labels) ","metadata":{"execution":{"iopub.status.busy":"2022-02-16T06:38:07.188831Z","iopub.execute_input":"2022-02-16T06:38:07.189089Z","iopub.status.idle":"2022-02-16T06:38:07.196653Z","shell.execute_reply.started":"2022-02-16T06:38:07.189059Z","shell.execute_reply":"2022-02-16T06:38:07.195589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 3\n\nfor epoch in range(epochs):\n    run_training_loop(train_dl)\n    train_acc = metric.compute()['overall_accuracy']\n    \n    run_evaluation_loop(val_dl)\n    val_acc = metric.compute()['overall_accuracy']\n    \n    print(f\"epoch: {epoch} train_acc: {train_acc} val_acc: {val_acc}\")\n    \n    # save the model at the end of epoch\n    torch.save(model.state_dict(), f\"model-v{epoch}.pt\")","metadata":{"execution":{"iopub.status.busy":"2022-02-16T06:38:10.285407Z","iopub.execute_input":"2022-02-16T06:38:10.286137Z","iopub.status.idle":"2022-02-16T06:52:47.308945Z","shell.execute_reply.started":"2022-02-16T06:38:10.286092Z","shell.execute_reply":"2022-02-16T06:52:47.308023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_evaluation_loop(test_dl)\nmetric.compute()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T06:52:57.603449Z","iopub.execute_input":"2022-02-16T06:52:57.603714Z","iopub.status.idle":"2022-02-16T06:53:26.846832Z","shell.execute_reply.started":"2022-02-16T06:52:57.603684Z","shell.execute_reply":"2022-02-16T06:53:26.84604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_output(text):\n  text_split = text.split()\n  tokens = tokenizer(text_split, is_split_into_words=True, truncation=True, return_tensors='pt')\n  preds = model(**tokens)['logits'].argmax(dim=-1)\n\n  out = {}\n  last_b_tag = \"\"\n  for p, w_id in zip(preds[0], tokens.word_ids()):\n    if w_id!=None:\n      label = labels[p]\n      label_split = label.split('-')\n      word = text_split[w_id]\n      \n      if word not in out.keys():\n        if label_split[0]=='I' and label_split[-1]==last_b_tag.split('-')[-1]:\n          old_key = list(out.keys())[-1]\n          new_key = old_key+f\" {word}\"\n          out.pop(old_key)\n          out[new_key] = last_b_tag\n        else:\n          out[word] = label\n          \n        if (label_split[0]=='B') and (label_split[-1] in ['ORG', 'LOC']):\n          last_b_tag = label\n\n  out_text = \"\"\n  for word, tag in out.items():\n    if tag.split('-')[-1] in ['PER', 'LOC', 'ORG']:\n      try:\n        word = word2vec.most_similar(positive=['India', word.replace(' ', '_')], negative=['USA'], topn=1)[0][0]\n      except KeyError:\n        pass\n    out_text += f\"{word.replace('_', ' ')} \"\n  return out_text","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prepare_output(\"My name is Sarah and I work at San Francisco\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"interface = gr.Interface(\n    prepare_output,\n    inputs=gr.inputs.Textbox(label=\"Input text\", lines=3),\n    outputs=gr.outputs.Textbox(label=\"Output text\"),\n)\n\n# launch the demo\ninterface.launch()","metadata":{},"execution_count":null,"outputs":[]}]}