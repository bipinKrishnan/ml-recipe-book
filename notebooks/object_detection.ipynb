{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nfrom torchvision.ops import box_iou\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models.detection import fasterrcnn_resnet50_fpn\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom pytorch_lightning import LightningModule, Trainer\n\nimport cv2\nfrom pathlib import Path\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2","metadata":{"execution":{"iopub.status.busy":"2022-04-23T07:17:29.014585Z","iopub.execute_input":"2022-04-23T07:17:29.015138Z","iopub.status.idle":"2022-04-23T07:17:29.020406Z","shell.execute_reply.started":"2022-04-23T07:17:29.015094Z","shell.execute_reply":"2022-04-23T07:17:29.019647Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/car-object-detection/data/train_solution_bounding_boxes (1).csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T07:17:29.042106Z","iopub.execute_input":"2022-04-23T07:17:29.042434Z","iopub.status.idle":"2022-04-23T07:17:29.059642Z","shell.execute_reply.started":"2022-04-23T07:17:29.042397Z","shell.execute_reply":"2022-04-23T07:17:29.058965Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"df['bbox_width'] = df['xmax']-df['xmin']\ndf['bbox_height'] = df['ymax']-df['ymin']\n\ndf['area'] = df['bbox_width']*df['bbox_height']","metadata":{"execution":{"iopub.status.busy":"2022-04-23T07:17:29.067880Z","iopub.execute_input":"2022-04-23T07:17:29.068114Z","iopub.status.idle":"2022-04-23T07:17:29.076580Z","shell.execute_reply.started":"2022-04-23T07:17:29.068069Z","shell.execute_reply":"2022-04-23T07:17:29.075871Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# group by similar image names\ndf = df.groupby('image').agg(list)\ndf.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T07:17:29.113936Z","iopub.execute_input":"2022-04-23T07:17:29.114264Z","iopub.status.idle":"2022-04-23T07:17:29.150835Z","shell.execute_reply.started":"2022-04-23T07:17:29.114234Z","shell.execute_reply":"2022-04-23T07:17:29.150043Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_df, val_df = train_test_split(df, test_size=0.1, shuffle=False)\ntrain_df.reset_index(inplace=True)\nval_df.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T07:17:29.152412Z","iopub.execute_input":"2022-04-23T07:17:29.152798Z","iopub.status.idle":"2022-04-23T07:17:29.160017Z","shell.execute_reply.started":"2022-04-23T07:17:29.152762Z","shell.execute_reply":"2022-04-23T07:17:29.159388Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"img_root_path = Path(\"../input/car-object-detection/data/training_images\")\n                     \nsample = train_df.iloc[215]\nimg_name = sample['image']\nbboxes = sample[['xmin', 'ymin', 'xmax', 'ymax']].values","metadata":{"execution":{"iopub.status.busy":"2022-04-23T07:17:29.236184Z","iopub.execute_input":"2022-04-23T07:17:29.236656Z","iopub.status.idle":"2022-04-23T07:17:29.241848Z","shell.execute_reply.started":"2022-04-23T07:17:29.236624Z","shell.execute_reply":"2022-04-23T07:17:29.241147Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"img = cv2.imread(str(img_root_path/img_name))\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)/255.0\n\nbboxes = tuple(map(torch.tensor, zip(*bboxes)))\nbboxes = torch.stack(bboxes, dim=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T07:17:29.352427Z","iopub.execute_input":"2022-04-23T07:17:29.352898Z","iopub.status.idle":"2022-04-23T07:17:29.366433Z","shell.execute_reply.started":"2022-04-23T07:17:29.352863Z","shell.execute_reply":"2022-04-23T07:17:29.365769Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"labels = torch.ones(len(bboxes), dtype=torch.int64)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T07:17:29.459459Z","iopub.execute_input":"2022-04-23T07:17:29.460040Z","iopub.status.idle":"2022-04-23T07:17:29.465667Z","shell.execute_reply.started":"2022-04-23T07:17:29.459935Z","shell.execute_reply":"2022-04-23T07:17:29.464722Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"transforms = A.Compose([\n    A.Resize(256, 256, p=1.0),\n    ToTensorV2(p=1.0),\n], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})","metadata":{"execution":{"iopub.status.busy":"2022-04-23T07:17:29.583251Z","iopub.execute_input":"2022-04-23T07:17:29.583688Z","iopub.status.idle":"2022-04-23T07:17:29.587842Z","shell.execute_reply.started":"2022-04-23T07:17:29.583653Z","shell.execute_reply":"2022-04-23T07:17:29.587145Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"augmented = transforms(image=img, bboxes=bboxes, labels=labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T07:17:29.684381Z","iopub.execute_input":"2022-04-23T07:17:29.685070Z","iopub.status.idle":"2022-04-23T07:17:29.698701Z","shell.execute_reply.started":"2022-04-23T07:17:29.685031Z","shell.execute_reply":"2022-04-23T07:17:29.698030Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"torch.stack(tuple(map(torch.tensor, zip(*augmented['bboxes'])))).permute(1, 0).type(torch.float32)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T07:17:29.804489Z","iopub.execute_input":"2022-04-23T07:17:29.805181Z","iopub.status.idle":"2022-04-23T07:17:29.813711Z","shell.execute_reply.started":"2022-04-23T07:17:29.805148Z","shell.execute_reply":"2022-04-23T07:17:29.812901Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"bboxes = map(torch.tensor, zip(*augmented['bboxes']))\nbboxes = tuple(bboxes)\nbboxes = torch.stack(bboxes, dim=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T07:17:29.905525Z","iopub.execute_input":"2022-04-23T07:17:29.905775Z","iopub.status.idle":"2022-04-23T07:17:29.910257Z","shell.execute_reply.started":"2022-04-23T07:17:29.905748Z","shell.execute_reply":"2022-04-23T07:17:29.909323Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"img = augmented['image'].type(torch.float32)\nbboxes = bboxes.permute(1, 0).type(torch.float32)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T07:17:30.053507Z","iopub.execute_input":"2022-04-23T07:17:30.054066Z","iopub.status.idle":"2022-04-23T07:17:30.058879Z","shell.execute_reply.started":"2022-04-23T07:17:30.054026Z","shell.execute_reply":"2022-04-23T07:17:30.057854Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"area = sample['area']\niscrowd = torch.zeros(len(bboxes), dtype=torch.int)\n\ntarget = {}\ntarget['boxes'] = bboxes\ntarget['labels'] = labels\ntarget['area'] = torch.as_tensor(area, dtype=torch.float32)\ntarget['iscrowd'] = iscrowd","metadata":{"execution":{"iopub.status.busy":"2022-04-23T07:17:30.208596Z","iopub.execute_input":"2022-04-23T07:17:30.209400Z","iopub.status.idle":"2022-04-23T07:17:30.214522Z","shell.execute_reply.started":"2022-04-23T07:17:30.209364Z","shell.execute_reply":"2022-04-23T07:17:30.213548Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"class LoadDataset(Dataset):\n    def __init__(self, df, img_dir, transforms):\n        super().__init__()\n        self.df = df\n        self.img_dir = img_dir\n        self.transforms = transforms\n        \n    def __len__(self): return len(self.df)\n    \n    def __getitem__(self, idx):\n        # read & process the image\n        filename = self.df.loc[idx, 'image']\n        img = cv2.imread(str(self.img_dir/filename))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)/255.0\n        \n        # get the bboxes\n        bboxes = self.df.loc[idx, ['xmin', 'ymin', 'xmax', 'ymax']].values\n        bboxes = tuple(map(torch.tensor, zip(*bboxes)))\n        bboxes = torch.stack(bboxes, dim=0)\n        \n        # create labels\n        labels = torch.ones(len(bboxes), dtype=torch.int64)\n        # apply augmentations\n        augmented = self.transforms(image=img, bboxes=bboxes, labels=labels)\n        \n        # convert bbox list to tensors again\n        bboxes = map(torch.tensor, zip(*augmented['bboxes']))\n        bboxes = tuple(bboxes)\n        bboxes = torch.stack(bboxes, dim=0)\n        \n        img = augmented['image'].type(torch.float32)\n        bboxes = bboxes.permute(1, 0).type(torch.float32)\n        iscrowd = torch.zeros(len(bboxes), dtype=torch.int)\n        \n        # bbox area\n        area = self.df.loc[idx, 'area']\n        torch.as_tensor(area, dtype=torch.float32)\n\n        target = {}\n        target['boxes'] = bboxes\n        target['labels'] = labels\n        target['area'] = area\n        target['iscrowd'] = iscrowd\n        \n        return img, target","metadata":{"execution":{"iopub.status.busy":"2022-04-23T07:17:30.416620Z","iopub.execute_input":"2022-04-23T07:17:30.417170Z","iopub.status.idle":"2022-04-23T07:17:30.428861Z","shell.execute_reply.started":"2022-04-23T07:17:30.417135Z","shell.execute_reply":"2022-04-23T07:17:30.427430Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"train_ds = LoadDataset(train_df, img_root_path, transforms)\nval_ds = LoadDataset(val_df, img_root_path, transforms)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T07:17:30.568288Z","iopub.execute_input":"2022-04-23T07:17:30.568541Z","iopub.status.idle":"2022-04-23T07:17:30.572910Z","shell.execute_reply.started":"2022-04-23T07:17:30.568512Z","shell.execute_reply":"2022-04-23T07:17:30.571929Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"model = fasterrcnn_resnet50_fpn(pretrained=True)\n\n# get input features of classification layer\nin_features = model.roi_heads.box_predictor.cls_score.in_features\n\n# modify the classifier layer with number of classes\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes=2)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T07:17:30.692557Z","iopub.execute_input":"2022-04-23T07:17:30.693096Z","iopub.status.idle":"2022-04-23T07:17:31.415269Z","shell.execute_reply.started":"2022-04-23T07:17:30.693043Z","shell.execute_reply":"2022-04-23T07:17:31.414530Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"class ObjectDetector(LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.lr = 1e-3\n        self.batch_size = 16\n        self.model = self.create_model()\n        \n    def create_model(self):\n        model = fasterrcnn_resnet50_fpn(pretrained=True)\n        in_features = model.roi_heads.box_predictor.cls_score.in_features\n        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes=2)\n        return model\n\n    def forward(self, x):\n        return self.model(x)\n\n    def collate_fn(self, batch):\n        return tuple(zip(*batch))\n\n    def train_dataloader(self):\n        return DataLoader(\n            train_ds, \n            batch_size=self.batch_size, \n            shuffle=True, \n            collate_fn=self.collate_fn\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            val_ds, \n            batch_size=self.batch_size, \n            shuffle=False, \n            collate_fn=self.collate_fn\n        )\n\n    def configure_optimizers(self):\n        return torch.optim.AdamW(self.model.parameters(), lr=self.lr)\n\n    def training_step(self, batch, batch_idx):\n        inputs, targets = batch\n        loss_dict = self.model(inputs, targets)\n        complete_loss = sum(loss for loss in loss_dict.values())\n        \n        self.log(\"train_loss\", complete_loss, prog_bar=True)\n        return {'loss': complete_loss}\n\n    def validation_step(self, batch, batch_idx):\n            inputs, targets = batch\n            outputs = self.model(inputs)\n            # calculate IOU and return the mean IOU\n            iou = torch.stack(\n                [box_iou(target['boxes'], output['boxes']).diag().mean() for target, output in zip(targets, outputs)]\n            ).mean()\n            \n            return {\"val_iou\": iou}\n\n    def validation_epoch_end(self, val_out):\n        # calculate overall IOU across batch\n        val_iou = torch.stack([o['val_iou'] for o in val_out]).mean()\n        self.log(\"val_iou\", val_iou, prog_bar=True)\n        return val_iou","metadata":{"execution":{"iopub.status.busy":"2022-04-23T07:17:31.417307Z","iopub.execute_input":"2022-04-23T07:17:31.417752Z","iopub.status.idle":"2022-04-23T07:17:31.431213Z","shell.execute_reply.started":"2022-04-23T07:17:31.417715Z","shell.execute_reply":"2022-04-23T07:17:31.430229Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"detector_model = ObjectDetector()\ntrainer = Trainer(\n    accelerator='auto',\n    devices=1,\n    auto_lr_find=True,\n    max_epochs=5,\n)\n\ntrainer.tune(detector_model)\ntrainer.fit(detector_model)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T07:26:32.022211Z","iopub.execute_input":"2022-04-23T07:26:32.022623Z","iopub.status.idle":"2022-04-23T07:32:47.440725Z","shell.execute_reply.started":"2022-04-23T07:26:32.022579Z","shell.execute_reply":"2022-04-23T07:32:47.439991Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nsample = val_ds[14]\nimg = sample[0]\n\ndetector_model.eval()\nwith torch.no_grad():\n    out = detector_model([img])\n    \n# convert to numpy for opencv to draw bboxes\nimg = img.permute(1, 2, 0).numpy()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T07:39:04.662597Z","iopub.execute_input":"2022-04-23T07:39:04.663176Z","iopub.status.idle":"2022-04-23T07:39:07.859404Z","shell.execute_reply.started":"2022-04-23T07:39:04.663139Z","shell.execute_reply":"2022-04-23T07:39:07.858483Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"# predicted bounding boxes    \npred_bbox = out[0]['boxes'].numpy().astype(int)\npred_label = out[0]['scores']\n\n# draw bounding boxes on the image\nfor bbox, label in zip(pred_bbox, pred_label):\n    # check if the predicted label is for car\n    if label>=0.5:\n        cv2.rectangle(\n            img,\n            (bbox[0], bbox[1]),\n            (bbox[2], bbox[3]),\n            (255, 0, 0), thickness=2,\n        )\n    \nplt.figure(figsize=(16, 6))\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T07:39:09.005557Z","iopub.execute_input":"2022-04-23T07:39:09.006247Z","iopub.status.idle":"2022-04-23T07:39:09.297637Z","shell.execute_reply.started":"2022-04-23T07:39:09.006205Z","shell.execute_reply":"2022-04-23T07:39:09.296988Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}