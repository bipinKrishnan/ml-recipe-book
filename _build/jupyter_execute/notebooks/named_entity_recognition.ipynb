{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-17T05:23:52.44216Z",
     "iopub.status.busy": "2022-02-17T05:23:52.441708Z",
     "iopub.status.idle": "2022-02-17T05:24:13.226907Z",
     "shell.execute_reply": "2022-02-17T05:24:13.225997Z",
     "shell.execute_reply.started": "2022-02-17T05:23:52.442054Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q datasets accelerate seqeval transformers \n",
    "!pip install gensim==4.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T06:35:15.362392Z",
     "iopub.status.busy": "2022-02-16T06:35:15.362115Z",
     "iopub.status.idle": "2022-02-16T06:35:21.783664Z",
     "shell.execute_reply": "2022-02-16T06:35:21.782923Z",
     "shell.execute_reply.started": "2022-02-16T06:35:15.362357Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    DataCollatorForTokenClassification, \n",
    "    AutoModelForTokenClassification\n",
    ")\n",
    "\n",
    "from accelerate import Accelerator\n",
    "import gensim.downloader as api\n",
    "import gradio as gr\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T06:35:25.806303Z",
     "iopub.status.busy": "2022-02-16T06:35:25.805883Z",
     "iopub.status.idle": "2022-02-16T06:35:36.212039Z",
     "shell.execute_reply": "2022-02-16T06:35:36.211383Z",
     "shell.execute_reply.started": "2022-02-16T06:35:25.806268Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = 'bert-base-cased'\n",
    "raw_datasets = load_dataset(\"conllpp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T06:35:39.245967Z",
     "iopub.status.busy": "2022-02-16T06:35:39.245712Z",
     "iopub.status.idle": "2022-02-16T06:35:45.011717Z",
     "shell.execute_reply": "2022-02-16T06:35:45.010873Z",
     "shell.execute_reply.started": "2022-02-16T06:35:39.245937Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T06:35:47.563023Z",
     "iopub.status.busy": "2022-02-16T06:35:47.562766Z",
     "iopub.status.idle": "2022-02-16T06:35:47.571429Z",
     "shell.execute_reply": "2022-02-16T06:35:47.570675Z",
     "shell.execute_reply.started": "2022-02-16T06:35:47.562992Z"
    }
   },
   "outputs": [],
   "source": [
    "train_row_1 = raw_datasets['train'][0]\n",
    "inputs = tokenizer(train_row_1['tokens'], is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T06:35:50.125435Z",
     "iopub.status.busy": "2022-02-16T06:35:50.124779Z",
     "iopub.status.idle": "2022-02-16T06:35:50.133142Z",
     "shell.execute_reply": "2022-02-16T06:35:50.13247Z",
     "shell.execute_reply.started": "2022-02-16T06:35:50.125395Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = raw_datasets['train'].features['ner_tags'].feature.names\n",
    "ids = range(len(labels))\n",
    "id2label = dict(zip(ids, labels))\n",
    "\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T06:35:50.567155Z",
     "iopub.status.busy": "2022-02-16T06:35:50.566648Z",
     "iopub.status.idle": "2022-02-16T06:35:50.57495Z",
     "shell.execute_reply": "2022-02-16T06:35:50.572243Z",
     "shell.execute_reply.started": "2022-02-16T06:35:50.567119Z"
    }
   },
   "outputs": [],
   "source": [
    "def align_tokens_and_labels(word_ids, labels):\n",
    "    previous_word_id = None\n",
    "    new_labels = []\n",
    "    \n",
    "    for word_id in word_ids:\n",
    "        \n",
    "        if word_id!=previous_word_id:\n",
    "            label = -100 if word_id==None else labels[word_id]\n",
    "        elif word_id==None:\n",
    "            label = -100\n",
    "        else:\n",
    "            label = labels[word_id]\n",
    "            if label%2==1:\n",
    "                label += 1\n",
    "                \n",
    "        previous_word_id = word_id\n",
    "        new_labels.append(label)\n",
    "                \n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T06:35:51.105647Z",
     "iopub.status.busy": "2022-02-16T06:35:51.104899Z",
     "iopub.status.idle": "2022-02-16T06:35:51.112502Z",
     "shell.execute_reply": "2022-02-16T06:35:51.111663Z",
     "shell.execute_reply.started": "2022-02-16T06:35:51.105607Z"
    }
   },
   "outputs": [],
   "source": [
    "ner_labels = train_row_1['ner_tags']\n",
    "inputs = tokenizer(train_row_1['tokens'], is_split_into_words=True)\n",
    "word_ids = inputs.word_ids()\n",
    "\n",
    "align_tokens_and_labels(word_ids, ner_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T06:35:53.755128Z",
     "iopub.status.busy": "2022-02-16T06:35:53.754485Z",
     "iopub.status.idle": "2022-02-16T06:35:59.199548Z",
     "shell.execute_reply": "2022-02-16T06:35:59.198821Z",
     "shell.execute_reply.started": "2022-02-16T06:35:53.755093Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_inputs_and_labels(ds):\n",
    "    inputs = tokenizer(ds['tokens'], truncation=True, padding=True, is_split_into_words=True)\n",
    "    labels_batch = ds['ner_tags']\n",
    "    \n",
    "    new_labels = []\n",
    "    for idx, labels in enumerate(labels_batch):\n",
    "        word_ids = inputs.word_ids(idx)\n",
    "        new_label = align_tokens_and_labels(word_ids, labels)\n",
    "        new_labels.append(new_label)\n",
    "        \n",
    "    inputs['labels'] = new_labels\n",
    "    return inputs\n",
    "\n",
    "prepared_datasets = raw_datasets.map(\n",
    "    prepare_inputs_and_labels, \n",
    "    batched=True, \n",
    "    remove_columns=raw_datasets['train'].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T06:36:00.604666Z",
     "iopub.status.busy": "2022-02-16T06:36:00.604063Z",
     "iopub.status.idle": "2022-02-16T06:36:00.610706Z",
     "shell.execute_reply": "2022-02-16T06:36:00.609632Z",
     "shell.execute_reply.started": "2022-02-16T06:36:00.604625Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "collate_fn = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "# training dataloader\n",
    "train_dl = DataLoader(\n",
    "    prepared_datasets['train'], \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "# validation dataloader\n",
    "val_dl = DataLoader(\n",
    "    prepared_datasets['validation'], \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "# test dataloader\n",
    "test_dl = DataLoader(\n",
    "    prepared_datasets['test'], \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    collate_fn=collate_fn\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T06:37:37.653912Z",
     "iopub.status.busy": "2022-02-16T06:37:37.653248Z",
     "iopub.status.idle": "2022-02-16T06:37:40.021326Z",
     "shell.execute_reply": "2022-02-16T06:37:40.020594Z",
     "shell.execute_reply.started": "2022-02-16T06:37:37.653877Z"
    }
   },
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    checkpoint, \n",
    "    num_labels=len(labels)\n",
    "    )\n",
    "opt = optim.AdamW(model.parameters(), lr=1.23e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T06:37:54.304152Z",
     "iopub.status.busy": "2022-02-16T06:37:54.303886Z",
     "iopub.status.idle": "2022-02-16T06:37:54.314506Z",
     "shell.execute_reply": "2022-02-16T06:37:54.313692Z",
     "shell.execute_reply.started": "2022-02-16T06:37:54.304123Z"
    }
   },
   "outputs": [],
   "source": [
    "accelerator = Accelerator()\n",
    "train_dl, val_dl, test_dl, model, opt = accelerator.prepare(\n",
    "    train_dl, \n",
    "    val_dl, \n",
    "    test_dl, \n",
    "    model, \n",
    "    opt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T06:37:55.503413Z",
     "iopub.status.busy": "2022-02-16T06:37:55.502913Z",
     "iopub.status.idle": "2022-02-16T06:37:56.056648Z",
     "shell.execute_reply": "2022-02-16T06:37:56.055958Z",
     "shell.execute_reply.started": "2022-02-16T06:37:55.503373Z"
    }
   },
   "outputs": [],
   "source": [
    "metric = load_metric('seqeval')\n",
    "\n",
    "targets = ['O', 'B-PER', 'I-PER', 'O', 'O', 'O']\n",
    "predictions = ['O', 'B-PER', 'O', 'O', 'O', 'O']\n",
    "\n",
    "metric.compute(predictions=[predictions], references=[targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T06:37:56.330044Z",
     "iopub.status.busy": "2022-02-16T06:37:56.329828Z",
     "iopub.status.idle": "2022-02-16T06:37:56.336391Z",
     "shell.execute_reply": "2022-02-16T06:37:56.335435Z",
     "shell.execute_reply.started": "2022-02-16T06:37:56.330018Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_preds_and_labels(preds, targets):\n",
    "    preds = preds.detach().cpu()\n",
    "    preds = preds.argmax(dim=-1)\n",
    "    targets = targets.detach().cpu()\n",
    "\n",
    "    true_targets = [\n",
    "        [labels[t.item()] for t in target if t!=-100] \n",
    "        for target in targets\n",
    "        ]\n",
    "    true_preds = [\n",
    "        [labels[p.item()] for p, t in zip(pred, target) if t!=-100] \n",
    "        for pred, target in zip(preds, targets)\n",
    "        ]\n",
    "\n",
    "    return true_preds, true_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(iter(train_dl))\n",
    "\n",
    "preds = model(**first_batch)\n",
    "process_preds_and_labels(preds.logits, first_batch['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T06:38:07.189089Z",
     "iopub.status.busy": "2022-02-16T06:38:07.188831Z",
     "iopub.status.idle": "2022-02-16T06:38:07.196653Z",
     "shell.execute_reply": "2022-02-16T06:38:07.195589Z",
     "shell.execute_reply.started": "2022-02-16T06:38:07.189059Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_training_loop(train_dl):\n",
    "    model.train()\n",
    "    for batch in tqdm(train_dl, total=len(train_dl)):\n",
    "        opt.zero_grad()\n",
    "        out = model(**batch)\n",
    "        accelerator.backward(out.loss)\n",
    "        opt.step()\n",
    "        \n",
    "        # convert target labels and predictions to string format for computing accuracy\n",
    "        preds, labels = process_preds_and_labels(out.logits, batch['labels'])\n",
    "        # add the target labels and predictions of this batch to seqeval\n",
    "        metric.add_batch(predictions=preds, references=labels)\n",
    "\n",
    "def run_evaluation_loop(test_dl):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dl, total=len(test_dl)):\n",
    "            out = model(**batch)\n",
    "            \n",
    "            # convert target labels and predictions to string format for computing accuracy\n",
    "            preds, labels = process_preds_and_labels(out.logits, batch['labels'])\n",
    "            # add the target labels and predictions of this batch to seqeval\n",
    "            metric.add_batch(predictions=preds, references=labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T06:38:10.286137Z",
     "iopub.status.busy": "2022-02-16T06:38:10.285407Z",
     "iopub.status.idle": "2022-02-16T06:52:47.308945Z",
     "shell.execute_reply": "2022-02-16T06:52:47.308023Z",
     "shell.execute_reply.started": "2022-02-16T06:38:10.286092Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    run_training_loop(train_dl)\n",
    "    train_acc = metric.compute()['overall_accuracy']\n",
    "    \n",
    "    run_evaluation_loop(val_dl)\n",
    "    val_acc = metric.compute()['overall_accuracy']\n",
    "    \n",
    "    print(f\"epoch: {epoch} train_acc: {train_acc} val_acc: {val_acc}\")\n",
    "    \n",
    "    # save the model at the end of epoch\n",
    "    torch.save(model.state_dict(), f\"model-v{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T06:52:57.603714Z",
     "iopub.status.busy": "2022-02-16T06:52:57.603449Z",
     "iopub.status.idle": "2022-02-16T06:53:26.846832Z",
     "shell.execute_reply": "2022-02-16T06:53:26.84604Z",
     "shell.execute_reply.started": "2022-02-16T06:52:57.603684Z"
    }
   },
   "outputs": [],
   "source": [
    "run_evaluation_loop(test_dl)\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_output(text):\n",
    "  text_split = text.split()\n",
    "  tokens = tokenizer(text_split, is_split_into_words=True, truncation=True, return_tensors='pt')\n",
    "  preds = model(**tokens)['logits'].argmax(dim=-1)\n",
    "\n",
    "  out = {}\n",
    "  last_b_tag = \"\"\n",
    "  for p, w_id in zip(preds[0], tokens.word_ids()):\n",
    "    if w_id!=None:\n",
    "      label = labels[p]\n",
    "      label_split = label.split('-')\n",
    "      word = text_split[w_id]\n",
    "      \n",
    "      if word not in out.keys():\n",
    "        if label_split[0]=='I' and label_split[-1]==last_b_tag.split('-')[-1]:\n",
    "          old_key = list(out.keys())[-1]\n",
    "          new_key = old_key+f\" {word}\"\n",
    "          out.pop(old_key)\n",
    "          out[new_key] = last_b_tag\n",
    "        else:\n",
    "          out[word] = label\n",
    "          \n",
    "        if (label_split[0]=='B') and (label_split[-1] in ['ORG', 'LOC']):\n",
    "          last_b_tag = label\n",
    "\n",
    "  out_text = \"\"\n",
    "  for word, tag in out.items():\n",
    "    if tag.split('-')[-1] in ['PER', 'LOC', 'ORG']:\n",
    "      try:\n",
    "        word = word2vec.most_similar(positive=['India', word.replace(' ', '_')], negative=['USA'], topn=1)[0][0]\n",
    "      except KeyError:\n",
    "        pass\n",
    "    out_text += f\"{word.replace('_', ' ')} \"\n",
    "  return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_output(\"My name is Sarah and I work at San Francisco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = gr.Interface(\n",
    "    prepare_output,\n",
    "    inputs=gr.inputs.Textbox(label=\"Input text\", lines=3),\n",
    "    outputs=gr.outputs.Textbox(label=\"Output text\"),\n",
    ")\n",
    "\n",
    "# launch the demo\n",
    "interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}