{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:39:02.268750Z",
     "iopub.status.busy": "2022-02-26T05:39:02.268482Z",
     "iopub.status.idle": "2022-02-26T05:39:09.704587Z",
     "shell.execute_reply": "2022-02-26T05:39:09.703678Z",
     "shell.execute_reply.started": "2022-02-26T05:39:02.268716Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:39:09.707617Z",
     "iopub.status.busy": "2022-02-26T05:39:09.707285Z",
     "iopub.status.idle": "2022-02-26T05:39:09.714239Z",
     "shell.execute_reply": "2022-02-26T05:39:09.713519Z",
     "shell.execute_reply.started": "2022-02-26T05:39:09.707561Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    DataCollatorForLanguageModeling,\n",
    "    default_data_collator,\n",
    "    AutoModelForMaskedLM,\n",
    ")\n",
    "\n",
    "from accelerate import Accelerator\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:40:21.130739Z",
     "iopub.status.busy": "2022-02-26T05:40:21.130447Z",
     "iopub.status.idle": "2022-02-26T05:42:02.017208Z",
     "shell.execute_reply": "2022-02-26T05:42:02.016507Z",
     "shell.execute_reply.started": "2022-02-26T05:40:21.130707Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_datasets = load_dataset('xsum')\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:44:30.446748Z",
     "iopub.status.busy": "2022-02-26T05:44:30.446432Z",
     "iopub.status.idle": "2022-02-26T05:44:30.474968Z",
     "shell.execute_reply": "2022-02-26T05:44:30.474268Z",
     "shell.execute_reply.started": "2022-02-26T05:44:30.446702Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = 10000\n",
    "test_size = int(0.2*train_size)\n",
    "seed = 42\n",
    "\n",
    "# 10,000 rows for training and 2000 rows for testing\n",
    "downsampled_datasets = raw_datasets['train'].train_test_split(\n",
    "    train_size=train_size,\n",
    "    test_size=test_size,\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "print(downsampled_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:44:30.704322Z",
     "iopub.status.busy": "2022-02-26T05:44:30.704070Z",
     "iopub.status.idle": "2022-02-26T05:44:36.479397Z",
     "shell.execute_reply": "2022-02-26T05:44:36.478663Z",
     "shell.execute_reply.started": "2022-02-26T05:44:30.704295Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = 'distilbert-base-uncased'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:44:37.443262Z",
     "iopub.status.busy": "2022-02-26T05:44:37.442471Z",
     "iopub.status.idle": "2022-02-26T05:44:37.449293Z",
     "shell.execute_reply": "2022-02-26T05:44:37.448637Z",
     "shell.execute_reply.started": "2022-02-26T05:44:37.443222Z"
    }
   },
   "outputs": [],
   "source": [
    "chunk_size = 128\n",
    "\n",
    "def create_chunks(examples):\n",
    "    # tokenize the inputs\n",
    "    inputs = tokenizer(examples['document'])\n",
    "    # cocatenate the inputs\n",
    "    concatenated_examples = {k: sum(v, []) for k, v in inputs.items()}\n",
    "    total_len = (len(concatenated_examples['input_ids'])//chunk_size)*chunk_size\n",
    "    \n",
    "    # create chunks of size 128\n",
    "    results = {\n",
    "        k: [v[i: (i+chunk_size)] for i in range(0, total_len, chunk_size)] \n",
    "        for k, v in concatenated_examples.items()\n",
    "        }\n",
    "    \n",
    "    results['labels'] = results['input_ids'].copy()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:44:39.103182Z",
     "iopub.status.busy": "2022-02-26T05:44:39.102472Z",
     "iopub.status.idle": "2022-02-26T05:45:18.707499Z",
     "shell.execute_reply": "2022-02-26T05:45:18.706756Z",
     "shell.execute_reply.started": "2022-02-26T05:44:39.103141Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessed_datasets = downsampled_datasets.map(\n",
    "    create_chunks, \n",
    "    batched=True, \n",
    "    remove_columns=['document', 'summary', 'id']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:45:22.902851Z",
     "iopub.status.busy": "2022-02-26T05:45:22.902192Z",
     "iopub.status.idle": "2022-02-26T05:45:22.912048Z",
     "shell.execute_reply": "2022-02-26T05:45:22.910653Z",
     "shell.execute_reply.started": "2022-02-26T05:45:22.902806Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = preprocessed_datasets['train'][:5]\n",
    "\n",
    "for i in sample['input_ids']:\n",
    "    input_length = len(i)\n",
    "    \n",
    "    print(input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:45:24.159949Z",
     "iopub.status.busy": "2022-02-26T05:45:24.159394Z",
     "iopub.status.idle": "2022-02-26T05:45:25.000661Z",
     "shell.execute_reply": "2022-02-26T05:45:24.999938Z",
     "shell.execute_reply.started": "2022-02-26T05:45:24.159909Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_inputs = sample['input_ids'][0]\n",
    "sample_labels = sample['labels'][0]\n",
    "\n",
    "# decode the tokens\n",
    "print(\"INPUTS:\\n\", tokenizer.decode(sample_inputs))\n",
    "print(\"\\nLABELS:\\n\", tokenizer.decode(sample_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:45:27.022588Z",
     "iopub.status.busy": "2022-02-26T05:45:27.022120Z",
     "iopub.status.idle": "2022-02-26T05:45:27.026062Z",
     "shell.execute_reply": "2022-02-26T05:45:27.025353Z",
     "shell.execute_reply.started": "2022-02-26T05:45:27.022549Z"
    }
   },
   "outputs": [],
   "source": [
    "collate_fn = DataCollatorForLanguageModeling(\n",
    "    tokenizer, \n",
    "    mlm_probability=0.15\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:45:30.719045Z",
     "iopub.status.busy": "2022-02-26T05:45:30.718399Z",
     "iopub.status.idle": "2022-02-26T05:45:30.724096Z",
     "shell.execute_reply": "2022-02-26T05:45:30.723254Z",
     "shell.execute_reply.started": "2022-02-26T05:45:30.719005Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in zip(sample):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:45:32.142314Z",
     "iopub.status.busy": "2022-02-26T05:45:32.141452Z",
     "iopub.status.idle": "2022-02-26T05:45:32.149132Z",
     "shell.execute_reply": "2022-02-26T05:45:32.148257Z",
     "shell.execute_reply.started": "2022-02-26T05:45:32.142262Z"
    }
   },
   "outputs": [],
   "source": [
    "# first 5 examples from train set\n",
    "first_5_rows = preprocessed_datasets['train'][:5]\n",
    "input_list = [dict(zip(first_5_rows, v)) for v in zip(*first_5_rows.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:45:39.723293Z",
     "iopub.status.busy": "2022-02-26T05:45:39.722541Z",
     "iopub.status.idle": "2022-02-26T05:45:39.728181Z",
     "shell.execute_reply": "2022-02-26T05:45:39.727449Z",
     "shell.execute_reply.started": "2022-02-26T05:45:39.723254Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    preprocessed_datasets['train'], \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:45:41.733495Z",
     "iopub.status.busy": "2022-02-26T05:45:41.732887Z",
     "iopub.status.idle": "2022-02-26T05:45:41.776372Z",
     "shell.execute_reply": "2022-02-26T05:45:41.775679Z",
     "shell.execute_reply.started": "2022-02-26T05:45:41.733453Z"
    }
   },
   "outputs": [],
   "source": [
    "next(iter(train_dl))['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:45:44.030216Z",
     "iopub.status.busy": "2022-02-26T05:45:44.029492Z",
     "iopub.status.idle": "2022-02-26T05:45:46.456377Z",
     "shell.execute_reply": "2022-02-26T05:45:46.455664Z",
     "shell.execute_reply.started": "2022-02-26T05:45:44.030178Z"
    }
   },
   "outputs": [],
   "source": [
    "def apply_random_mask(examples):\n",
    "    example_list = [dict(zip(examples, v)) for v in zip(*examples.values())]\n",
    "    output = collate_fn(example_list)\n",
    "    # we need to return a dictionary\n",
    "    return {k: v.numpy() for k, v in output.items()}\n",
    "\n",
    "test_dataset = preprocessed_datasets['test'].map(apply_random_mask, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:45:46.458255Z",
     "iopub.status.busy": "2022-02-26T05:45:46.457916Z",
     "iopub.status.idle": "2022-02-26T05:45:46.464202Z",
     "shell.execute_reply": "2022-02-26T05:45:46.463560Z",
     "shell.execute_reply.started": "2022-02-26T05:45:46.458216Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dl = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    collate_fn=default_data_collator\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:45:48.501840Z",
     "iopub.status.busy": "2022-02-26T05:45:48.501550Z",
     "iopub.status.idle": "2022-02-26T05:45:48.533948Z",
     "shell.execute_reply": "2022-02-26T05:45:48.533302Z",
     "shell.execute_reply.started": "2022-02-26T05:45:48.501810Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.decode(next(iter(test_dl))['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:49:36.041902Z",
     "iopub.status.busy": "2022-02-26T05:49:36.041126Z",
     "iopub.status.idle": "2022-02-26T05:49:38.295646Z",
     "shell.execute_reply": "2022-02-26T05:49:38.294751Z",
     "shell.execute_reply.started": "2022-02-26T05:49:36.041849Z"
    }
   },
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(checkpoint)\n",
    "opt = optim.AdamW(model.parameters(), lr=1.23e-5)\n",
    "\n",
    "accelerator = Accelerator()\n",
    "train_dl, test_dl, model, opt = accelerator.prepare(train_dl, test_dl, model, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:49:41.464310Z",
     "iopub.status.busy": "2022-02-26T05:49:41.464054Z",
     "iopub.status.idle": "2022-02-26T05:49:41.472783Z",
     "shell.execute_reply": "2022-02-26T05:49:41.471747Z",
     "shell.execute_reply.started": "2022-02-26T05:49:41.464282Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_training_loop(train_dl):\n",
    "    losses = 0\n",
    "    model.train()\n",
    "    for batch in tqdm(train_dl, total=len(train_dl)):\n",
    "        opt.zero_grad()\n",
    "        out = model(**batch)\n",
    "        accelerator.backward(out.loss)\n",
    "        opt.step()\n",
    "\n",
    "        losses += out.loss.item()\n",
    "#         break\n",
    "    losses /= len(train_dl)\n",
    "    # exponential of cross entropy\n",
    "    perplexity = math.exp(losses)\n",
    "    return perplexity\n",
    "\n",
    "def run_evaluation_loop(test_dl):\n",
    "    losses = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dl, total=len(test_dl)):\n",
    "            out = model(**batch)\n",
    "            losses += out.loss.item()\n",
    "#             break\n",
    "            \n",
    "    losses /= len(test_dl)\n",
    "    # exponential of cross entropy\n",
    "    perplexity = math.exp(losses)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T05:49:42.809187Z",
     "iopub.status.busy": "2022-02-26T05:49:42.808473Z",
     "iopub.status.idle": "2022-02-26T06:07:10.187574Z",
     "shell.execute_reply": "2022-02-26T06:07:10.186687Z",
     "shell.execute_reply.started": "2022-02-26T05:49:42.809148Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_perplexity = run_training_loop(train_dl)\n",
    "    test_perplexity = run_evaluation_loop(test_dl)\n",
    "    \n",
    "    print(f\"epoch: {epoch} train_acc: {train_perplexity} val_acc: {test_perplexity}\")\n",
    "    \n",
    "    # save the model at the end of epoch\n",
    "    torch.save(model.state_dict(), f\"model-v{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T06:09:43.269691Z",
     "iopub.status.busy": "2022-02-26T06:09:43.269236Z",
     "iopub.status.idle": "2022-02-26T06:09:43.288797Z",
     "shell.execute_reply": "2022-02-26T06:09:43.288074Z",
     "shell.execute_reply.started": "2022-02-26T06:09:43.269651Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Rajesh Shah, one of the shop's co-owners, told the [MASK] \n",
    "there would be a new name.\n",
    "\"\"\"\n",
    "\n",
    "# tokenize the inputs\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "inputs = inputs.to(accelerator.device)\n",
    "out = model(**inputs)\n",
    "\n",
    "# find the position in input where [MASK] is present\n",
    "mask_token_id = tokenizer.mask_token_id\n",
    "mask_idx = torch.where(inputs['input_ids']==mask_token_id)[1]\n",
    "\n",
    "# decode the prediction corresponding to [MASK]\n",
    "preds = out.logits.argmax(dim=-1)[0]\n",
    "mask_pred = tokenizer.decode(preds[mask_idx])\n",
    "\n",
    "# replace [MASK] with predicted word\n",
    "final_text = text.replace('[MASK]', mask_pred)\n",
    "print(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}